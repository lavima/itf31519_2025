{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3e62aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Softmax, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8452e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "(x_trainval, y_trainval), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46201ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b0058546490>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(x_trainval[0])\n",
    "plt.imshow(x_trainval[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "686e5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the data to verify the size of the provided partitions\n",
    "print(f'{x_trainval.shape} {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f98b8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Split training data into training and validation data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=10000, stratify=y_trainval)\n",
    "print(f'{x_train.shape} {x_val.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2db0c625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "079370ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_trainval = x_trainval / 255.0\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add extra dimension for channels\n",
    "x_trainval = x_trainval[..., tf.newaxis]\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_val = x_val[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Convert to 32 bit floating point\n",
    "x_trainval = x_trainval.astype('float32')\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "51c8da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1 = Sequential()\n",
    "nn1.add(Input(shape=(28,28,1)))\n",
    "nn1.add(Flatten())\n",
    "nn1.add(Dense(380))\n",
    "nn1.add(Dropout(rate=0.2))\n",
    "nn1.add(Dense(80))\n",
    "nn1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "nn1.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8663ce33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.4524 - val_accuracy: 0.9063 - val_loss: 0.3388\n",
      "Epoch 2/5\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.3286 - val_accuracy: 0.9040 - val_loss: 0.3329\n",
      "Epoch 3/5\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3160 - val_accuracy: 0.8987 - val_loss: 0.3657\n",
      "Epoch 4/5\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.3073 - val_accuracy: 0.9160 - val_loss: 0.3101\n",
      "Epoch 5/5\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.3019 - val_accuracy: 0.9006 - val_loss: 0.3399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b00bddb5590>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.fit(x_train, y_train, epochs=5, batch_size=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6cc9f15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn1.history.history['loss'], label='loss')\n",
    "plt.plot(nn1.history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3e1e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0709 - loss: 2.5993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.599270820617676, 0.07090000063180923]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62499338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:05:28.170925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.222270: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.231141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.254205: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.259752: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.302398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.319771: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.342102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.365529: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.404071: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.430765: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.472689: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.628931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.653721: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.707924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.717795: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.723156: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.742871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.755797: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.755843: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.771367: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.792996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.795488: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.801422: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.806307: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.806595: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:28.840910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.841348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.856029: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.879466: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.886723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:28.892503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 11:05:29.478020: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:29.693746: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:29.782108: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:29.879120: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:29.964903: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.162263: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.222879: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:30.223043: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:30.223057: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:30.223060: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:30.223201: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.223237: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.223240: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:30.262487: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.342277: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:30.342670: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:30.342787: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:30.342791: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:30.342935: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.342960: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.342962: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:30.438714: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:30.438868: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:30.438874: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:30.438877: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:30.439020: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.439049: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.439052: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:30.471023: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.591833: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:30.591952: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:30.591960: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:30.591964: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:30.592111: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.592137: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.592139: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:05:30.813330: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.816714: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.832921: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.846790: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.866931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.876676: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.880169: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-12 11:05:30.945841: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:30.945900: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:30.945913: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:30.945919: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:30.946244: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.946372: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:30.946385: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.002568: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.002626: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.002641: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.002646: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.002842: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.002890: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.002895: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.027885: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.027931: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.027937: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.027940: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.028135: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.028169: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.028172: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.094038: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:05:31.297489: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.297525: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.297529: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.297533: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.297677: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.297707: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.297710: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.522950: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.523199: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.523214: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.523218: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.523378: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.523412: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.523416: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.530175: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.530217: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.530221: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.530225: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.530344: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.530365: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.530368: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.651263: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.651304: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.651310: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.651313: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.651443: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.651470: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.651473: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.671912: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.672074: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.672118: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.672144: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.672335: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.672419: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.672443: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.708344: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.708470: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.708489: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.708502: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.708672: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.708713: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.708726: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "\u001b[1m   1/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26:12\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 2.3860Epoch 1/5\n",
      "\u001b[1m  29/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.0922 - loss: 2.4120Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:05:31.826588: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.826793: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.826809: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.826815: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.826946: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.827044: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.827086: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n",
      "2025-11-12 11:05:31.850427: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:31.850586: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:31.850640: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:31.850650: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:31.850784: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.850825: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:31.850832: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  41/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.1020 - loss: 2.3917Epoch 1/5\n",
      "\u001b[1m  83/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.1338 - loss: 2.3384Epoch 1/5\n",
      "Epoch 1/5\n",
      "\u001b[1m  43/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.1428 - loss: 2.3227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:05:32.031322: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-11-12 11:05:32.031701: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-12 11:05:32.031781: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: Tesla\n",
      "2025-11-12 11:05:32.031829: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: Tesla\n",
      "2025-11-12 11:05:32.032024: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-12 11:05:32.032161: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 580.95.5\n",
      "2025-11-12 11:05:32.032240: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 580.95.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 149/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.1799 - loss: 2.2805Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.6786\n",
      "\u001b[1m9246/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.9842Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.6871\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.6955\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.7341\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.7125\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.7337\n",
      "\u001b[1m9334/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 0.9678Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.6616\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.6669\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.6843\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.6595\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.6706\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.7346\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.7353\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.6970\n",
      "\u001b[1m 423/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.4799Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.6777\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.6428\n",
      "\u001b[1m2958/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.4753Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.4577\n",
      "\u001b[1m9484/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.4916Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.4424\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.4690\n",
      "\u001b[1m9546/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.4536Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.4468\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.4466\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4710\n",
      "\u001b[1m9424/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.4358Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.4434\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.4190\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.4574\n",
      "\u001b[1m9512/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8515 - loss: 0.4749Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.4242\n",
      "\u001b[1m  46/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.4958Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.4499\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.4491\n",
      "\u001b[1m 311/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.4519Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.4512\n",
      "\u001b[1m 318/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.4326Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.4285\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.4572\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.3961\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.4083\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.4074\n",
      "\u001b[1m 138/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: 0.4631Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.4060\n",
      "\u001b[1m9167/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.4064Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.4134\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.4011\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.3887\n",
      "\u001b[1m 240/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4484Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3976\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.3834\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3562\n",
      "\u001b[1m9459/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.3829Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.3906\n",
      "\u001b[1m 364/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.3913Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.4094\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3803\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3761\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3949\n",
      "\u001b[1m 264/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.8854 - loss: 0.3782Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3978\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3653\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3546\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.3825\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.3729\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.3541\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.3416\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.3537\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3573\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.3499\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.3454\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.3474\n",
      "\u001b[1m  92/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2726Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8906 - loss: 0.3494\n",
      "\u001b[1m 288/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.3934Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3630\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3584\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.3661\n",
      "\u001b[1m 320/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.3189Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.3927\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.3225\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.3508\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.3280\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.3373\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.3168\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3533\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.3292\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.3146\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.3417\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.3057\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 0.3230\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.3207\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 0.3300\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.3159\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3668\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.32\n",
      "\u001b[1m1884/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5cy: 0.9007 - loss: 0.\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.32\n",
      "\u001b[1m2170/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5cy: 0.9008 - loss: 0.32\n",
      "\u001b[1m2226/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5cy: 0.9008 - loss: 0.32\n",
      "Epoch 1/5\n",
      "\u001b[1m2304/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5cy: 0.9008 - loss: 0.32\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "\u001b[1m8551/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.3232Epoch 1/5\n",
      "\u001b[1m8577/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.3231Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m8623/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.3231Epoch 1/5\n",
      "\u001b[1m  94/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.1809 - loss: 2.3235Epoch 1/5\n",
      "\u001b[1m8756/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.3228Epoch 1/5\n",
      "\u001b[1m8904/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.3226Epoch 1/5\n",
      "\u001b[1m 112/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.2206 - loss: 2.2666Epoch 1/5\n",
      "\u001b[1m 188/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.2373 - loss: 2.2525Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.9044 - loss: 0.3073\n",
      "\u001b[1m 852/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.4825 - loss: 1.8804Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.6242\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.6500\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8305 - loss: 0.6092\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8270 - loss: 0.5888\n",
      "\u001b[1m8200/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.7414 - loss: 0.9497Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.5771\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8267 - loss: 0.6254\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.5933\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.5692\n",
      "\u001b[1m  70/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.3086Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.5749\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.5572\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.5743\n",
      "\u001b[1m9416/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7641 - loss: 0.8218Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8259 - loss: 0.5846\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.5696\n",
      "\u001b[1m 375/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.4270Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8281 - loss: 0.5804\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2890\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.6024\n",
      "Epoch 2/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/stepp - accuracy: 0.8653 - loss: 0.421\n",
      "\u001b[1m1662/9600\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.4546Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.3784\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8777 - loss: 0.3936\n",
      "\u001b[1m9119/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8775 - loss: 0.3934Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3822\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8791 - loss: 0.3896\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.3920\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.3929\n",
      "\u001b[1m9564/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3937Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8814 - loss: 0.3787\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8767 - loss: 0.3923\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.3657\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.3801\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 0.3705\n",
      "\u001b[1m 230/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.3314Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.3765\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8765 - loss: 0.3940\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8826 - loss: 0.3801\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.3785\n",
      "\u001b[1m2653/9600\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.3533Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 0.5829\n",
      "\u001b[1m3379/9600\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 6ms/step - accuracy: 0.8987 - loss: 0.3292Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.3350\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8950 - loss: 0.3397\n",
      "\u001b[1m  17/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.4045Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.3252\n",
      "\u001b[1m9344/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.3353Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.3395\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.3308\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.3438\n",
      "\u001b[1m9419/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.3353Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.9025 - loss: 0.3175\n",
      "\u001b[1m  75/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.4077Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.3253\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.3229\n",
      "\u001b[1m 116/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.3453Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8969 - loss: 0.3338\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.9036 - loss: 0.3131\n",
      "\u001b[1m6553/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8956 - loss: 0.3338Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.3182\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.8946 - loss: 0.3404\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.3199\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7ms/step - accuracy: 0.8997 - loss: 0.3228\n",
      "\u001b[1m3669/9600\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.3001Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7ms/step - accuracy: 0.8850 - loss: 0.3680\n",
      "\u001b[1m4483/9600\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.3087Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.3063\n",
      "\u001b[1m9321/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.3199Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.3147\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9106 - loss: 0.2894\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.3200\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.3136\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.2874\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.3017\n",
      "\u001b[1m9317/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.2855Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9092 - loss: 0.2913\n",
      "\u001b[1m4580/9600\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8975 - loss: 0.3284Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.2877\n",
      "\u001b[1m 438/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2762Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.2925\n",
      "\u001b[1m9482/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2946Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2840\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.3073\n",
      "\u001b[1m 447/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2836Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2923\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.2844\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7ms/step - accuracy: 0.9105 - loss: 0.2908\n",
      "\u001b[1m4316/9600\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.2789Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7ms/step - accuracy: 0.9015 - loss: 0.3199\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2908\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.2785\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.2808\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.2868\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2690\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.9108 - loss: 0.2871\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.2725\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.2686\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2627\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2718\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.2680\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9116 - loss: 0.2816\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2693\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9183 - loss: 0.26\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9009 - loss: 0.327\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9121 - loss: 0.272\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9010 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9011 - loss: 0.32\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "\u001b[1m1667/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/stepEpoch 1/5acy: 0.9011 - loss: 0.32\n",
      "\u001b[1m5523/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.2776Epoch 1/5\n",
      "\u001b[1m2314/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5acy: 0.9123 - loss: 0.27\n",
      "\u001b[1m1853/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5acy: 0.9182 - loss: 0.26\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepp - accuracy: 0.9124 - loss: 0.27\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepp - accuracy: 0.9182 - loss: 0.26\n",
      "\u001b[1m1917/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5acy: 0.9182 - loss: 0.26\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepp - accuracy: 0.9014 - loss: 0.322\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepp - accuracy: 0.9182 - loss: 0.262\n",
      "Epoch 1/5\n",
      "\u001b[1m  47/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.1262 - loss: 2.3616Epoch 1/5\n",
      "\u001b[1m7884/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2627Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepacy: 0.1524 - loss: 2.31oss: 0.277\n",
      "\u001b[1m   1/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28:01\u001b[0m 1s/step - accuracy: 0.2000 - loss: 2.1683Epoch 1/5\n",
      "\u001b[1m  59/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 6ms/step - accuracy: 0.1804 - loss: 2.3246Epoch 1/5\n",
      "\u001b[1m  92/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 7ms/step - accuracy: 0.2220 - loss: 2.2804Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.2619\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.6699 - loss: 1.190\n",
      "\u001b[1m2299/9600\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 7ms/step - accuracy: 0.6658 - loss: 1.1842Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.6700 - loss: 1.24\n",
      "\u001b[1m2891/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 7ms/step - accuracy: 0.6893 - loss: 1.1121Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2795\n",
      "\u001b[1m3160/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - accuracy: 0.6978 - loss: 1.0815Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.2709\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.3000\n",
      "Epoch 5/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/stepracy: 0.8995 - loss: 0.32oss: 1.318\n",
      "\u001b[1m 512/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 7ms/step - accuracy: 0.9015 - loss: 0.3149Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.8289 - loss: 0.6020\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.6113\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8361 - loss: 0.5840\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 0.5382\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8429 - loss: 0.5400\n",
      "\u001b[1m 210/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 7ms/step - accuracy: 0.8918 - loss: 0.4029Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 0.5580\n",
      "\u001b[1m5484/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2825Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 0.5439\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 0.5473\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 0.5487\n",
      "\u001b[1m9512/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3004 - loss: 2.9455Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.4073 - loss: 1.7929\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8423 - loss: 0.5376\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 0.5324\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.4252 - loss: 1.7247\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.5404\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.5364\n",
      "\u001b[1m3260/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.4230Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.2781\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.8833 - loss: 0.379\n",
      "\u001b[1m5288/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.8805 - loss: 0.3850Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5ms/step - accuracy: 0.6470 - loss: 0.9391\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.5605 - loss: 1.0686\n",
      "\u001b[1m7732/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.4040Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8855 - loss: 0.3698\n",
      "\u001b[1m8819/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.3779Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.3522\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.3710\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.3495\n",
      "\u001b[1m9094/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8847 - loss: 0.3717Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.3682\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8939 - loss: 0.3416\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8894 - loss: 0.3555\n",
      "\u001b[1m6432/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.8816 - loss: 0.3795Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8875 - loss: 0.3642\n",
      "\u001b[1m 151/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 8ms/step - accuracy: 0.8919 - loss: 0.3213Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.3588\n",
      "\u001b[1m3259/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - accuracy: 0.5741 - loss: 0.9730Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8889 - loss: 0.3560\n",
      "\u001b[1m 538/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 7ms/step - accuracy: 0.9109 - loss: 0.3094Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8899 - loss: 0.3524\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.4927 - loss: 1.6069\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8853 - loss: 0.3628\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.4556\n",
      "\u001b[1m3263/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 7ms/step - accuracy: 0.8993 - loss: 0.3213Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3544\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.8670\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.6178\n",
      "\u001b[1m8957/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8993 - loss: 0.3217Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.3203\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.9035 - loss: 0.3093\n",
      "\u001b[1m9424/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.3192Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.8997 - loss: 0.3230\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.3132\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.2947\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9041 - loss: 0.3097\n",
      "\u001b[1m  32/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 7ms/step - accuracy: 0.9263 - loss: 0.2917Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9049 - loss: 0.3064\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.8986 - loss: 0.3181\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9059 - loss: 0.3026\n",
      "\u001b[1m 511/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.2879Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9025 - loss: 0.3113\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9037 - loss: 0.3066\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - accuracy: 0.9064 - loss: 0.3046\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.3036\n",
      "\u001b[1m4906/9600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5985Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.9028 - loss: 0.3088\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.3585\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.2724\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.5668\n",
      "Epoch 5/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.8307 - loss: 0.487\n",
      "\u001b[1m7447/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9063 - loss: 0.3044Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2839\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 8ms/step - accuracy: 0.9103 - loss: 0.2928\n",
      "\u001b[1m8972/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9101 - loss: 0.2855Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.2631\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9151 - loss: 0.2739\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9170 - loss: 0.2682\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.2882\n",
      "\u001b[1m8339/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2747Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.2628\n",
      "\u001b[1m5629/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 0.4846Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 8ms/step - accuracy: 0.9140 - loss: 0.2758\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.2782\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.2653\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 8ms/step - accuracy: 0.9148 - loss: 0.2763\n",
      "\u001b[1m 981/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 8ms/step - accuracy: 0.9305 - loss: 0.2418Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.2879\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.8748 - loss: 0.4396\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9148 - loss: 0.2709\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - accuracy: 0.9154 - loss: 0.2756\n",
      "\u001b[1m8469/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 3.1583Epoch 5/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.9260 - loss: 0.2405\n",
      "\u001b[1m1011/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2505Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.6148 - loss: 1.4333\n",
      "\u001b[1m4260/9600\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9165 - loss: 0.2651Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.2764\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.2694\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - accuracy: 0.9206 - loss: 0.2541\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 8ms/step - accuracy: 0.9208 - loss: 0.2513\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 8ms/step - accuracy: 0.9247 - loss: 0.2418\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - accuracy: 0.9245 - loss: 0.2461\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 8ms/step - accuracy: 0.9185 - loss: 0.2636\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.9243 - loss: 0.2439\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.2548\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.9221 - loss: 0.2493\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.9200 - loss: 0.25\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2754\n",
      "\u001b[1m9422/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6256 - loss: 3.0222Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.4965\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 1.2355\n",
      "Epoch 2/5\n",
      "\u001b[1m2342/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5cy: 0.9161 - loss: 0.275\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2757\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.9378 - loss: 0.257\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepacy: 0.3799 - loss: 33.74ss: 0.254\n",
      "\u001b[1m 594/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2827Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.9248 - loss: 0.286\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2662\n",
      "\u001b[1m7910/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2559Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.8815 - loss: 0.45\n",
      "\u001b[1m 161/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.3070 - loss: 30.7305Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.8817 - loss: 0.4560\n",
      "\u001b[1m7159/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.2548Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.25503\n",
      "\u001b[1m1430/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.2965Epoch 1/5\n",
      "\u001b[1m1039/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 14.3261Epoch 1/5\n",
      "\u001b[1m1153/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.5902 - loss: 13.4639Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.9258 - loss: 0.3118\n",
      "\u001b[1m1866/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/stepEpoch 1/5acy: 0.6190 - loss: 11.746\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.5947 - loss: 12.910\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7ms/step - accuracy: 0.9232 - loss: 0.2484\n",
      "\u001b[1m2542/9600\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 6.7213Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.2577\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7ms/step - accuracy: 0.9238 - loss: 0.2434\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.2483 - loss: 7.936\n",
      "\u001b[1m2154/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5acy: 0.8840 - loss: 0.459\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.9235 - loss: 0.327\n",
      "\u001b[1m5839/9600\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.4542Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.3454 - loss: 8.48\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.3341\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.4161\n",
      "Epoch 3/5\n",
      "\u001b[1m7690/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7558 - loss: 3.6737Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 1.3597\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 1.1576\n",
      "\u001b[1m 253/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.8342 - loss: 0.6358Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 1.3947\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 1.0484\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 1.2510\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 1.3437\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 1.3662\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 1.2299\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 1.3203\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7905 - loss: 1.3707\n",
      "\u001b[1m1014/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.6545Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.2774 - loss: 2.0163\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5ms/step - accuracy: 0.4113 - loss: 1.8691\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.2644\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.3008\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - accuracy: 0.3600 - loss: 2.0931\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.4513\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.3904\n",
      "\u001b[1m9269/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.3067Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.2974\n",
      "\u001b[1m1083/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.3010Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.4010\n",
      "\u001b[1m7518/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2492 - loss: 3.3324Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9145 - loss: 0.3326\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.8723 - loss: 0.5707\n",
      "\u001b[1m9366/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.4029Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.5614\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.5212\n",
      "\u001b[1m1447/9600\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.3142 - loss: 1.7574Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.3413\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.5108\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.2418 - loss: 2.1362\n",
      "\u001b[1m1098/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.3690Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.2446\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.2642\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.3176\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2953\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6ms/step - accuracy: 0.3599 - loss: 1.5733\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.2504\n",
      "\u001b[1m4866/9600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.2426 - loss: 1.8890Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2845\n",
      "Epoch 4/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.3763\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2844\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.3735\n",
      "\u001b[1m9355/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.2805Epoch 4/5\n",
      "\u001b[1m1142/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.2780Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.3607\n",
      "\u001b[1m1246/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.2585Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.2781\n",
      "\u001b[1m 222/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.2312Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.3389\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.3572\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5ms/step - accuracy: 0.6080 - loss: 1.0220\n",
      "\u001b[1m1670/9600\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2523Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - accuracy: 0.4681 - loss: 1.4085\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5ms/step - accuracy: 0.2866 - loss: 1.7978\n",
      "\u001b[1m4874/9600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - accuracy: 0.4132 - loss: 1.3567Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.2386\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2782\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 0.2665\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.2308\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.2640\n",
      "\u001b[1m2243/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 5/5cy: 0.9221 - loss: 0.31\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.3661 - loss: 1.627\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.3212\n",
      "\u001b[1m 758/9600\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1707Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2564\n",
      "\u001b[1m9444/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.2904Epoch 5/5\n",
      "Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.2930\n",
      "\u001b[1m6227/9600\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.6155 - loss: 0.9971Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.3220\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2474\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.3097\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.5002 - loss: 1.2376\n",
      "\u001b[1m8549/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2364 - loss: 3.1720Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.2515 - loss: 2.1016\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.7334 - loss: 0.7395\n",
      "\u001b[1m3492/9600\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9253 - loss: 0.2929Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.6371 - loss: 0.9161\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.2486\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2611\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.2142\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6ms/step - accuracy: 0.4489 - loss: 1.4337\n",
      "Epoch 4/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.2500\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.3051\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.2401\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2733\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.3016\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.6983 - loss: 0.7472\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.2381\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.6984 - loss: 0.740\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.6990 - loss: 0.740\n",
      "\u001b[1m4254/9600\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.6068Epoch 1/5\n",
      "\u001b[1m2059/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepEpoch 1/5acy: 0.6907 - loss: 0.836\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.7815 - loss: 0.606\n",
      "\u001b[1m1244/2400\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/stepEpoch 1/5acy: 0.2885 - loss: 1.810\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.3039\n",
      "\u001b[1m4672/9600\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.7452Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.5479 - loss: 1.155\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 2.98148\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.5478 - loss: 1.158\n",
      "\u001b[1m  10/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.1008 - loss: 82.8066       Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/stepp - accuracy: 0.5479 - loss: 1.158\n",
      "\u001b[1m5036/9600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.6041Epoch 1/5\n",
      "\u001b[1m5592/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.2883 - loss: 1.8192Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "\u001b[1m1494/2400\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/stepEpoch 1/5acy: 0.7029 - loss: 0.743\n",
      "\u001b[1m5229/9600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.6036Epoch 1/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/stepp - accuracy: 0.6132 - loss: 12.991\n",
      "\u001b[1m1249/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 11.6597Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 1.0394\n",
      "\u001b[1m 971/9600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 6ms/step - accuracy: 0.6587 - loss: 13.0160Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6ms/step - accuracy: 0.7677 - loss: 0.7214\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.2889 - loss: 1.8042\n",
      "\u001b[1m3423/9600\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.7498 - loss: 8.2451Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6ms/step - accuracy: 0.7433 - loss: 0.7165\n",
      "Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 0.5656\n",
      "\u001b[1m3145/9600\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.3928Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.5778 - loss: 1.1177\n",
      "\u001b[1m7100/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.7897 - loss: 5.2642Epoch 5/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 1.2304\n",
      "\u001b[1m7777/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.3742Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.7169 - loss: 1.2875\n",
      "\u001b[1m8855/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 4.0617Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.8548 - loss: 1.1277\n",
      "\u001b[1m6429/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.4913Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 1.0588\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 1.3248\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.8618 - loss: 1.3534\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.8588 - loss: 1.4326\n",
      "\u001b[1m   1/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0430Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.8644 - loss: 1.2821\n",
      "\u001b[1m  62/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 5ms/step - accuracy: 0.8898 - loss: 0.3732Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 1.5530\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.3434\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7ms/step - accuracy: 0.2807 - loss: 2.1702\n",
      "Epoch 2/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.9004 - loss: 0.4354\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/stepp - accuracy: 0.2996 - loss: 1.753\n",
      "\u001b[1m5316/9600\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.3002 - loss: 1.7586Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.5500\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.8370 - loss: 0.4987\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.8791 - loss: 0.497\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/stepp - accuracy: 0.9066 - loss: 0.366\n",
      "\u001b[1m4436/9600\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - accuracy: 0.9327 - loss: 0.2807Epoch 1/5\n",
      "\u001b[1m3431/9600\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.2481 - loss: 1.9405Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.7191\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6ms/step - accuracy: 0.3252 - loss: 1.7077\n",
      "\u001b[1m2267/9600\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.3470 - loss: 6.3148Epoch 4/5\n",
      "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/stepp - accuracy: 0.2256 - loss: 3.946\n",
      "\u001b[1m8222/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9133 - loss: 0.3357Epoch 1/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.4072\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.4376\n",
      "Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.3184\n",
      "\u001b[1m9031/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.3296Epoch 3/5\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.3435\n",
      "\u001b[1m9080/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9175 - loss: 0.3272Epoch 3/5\n",
      "\u001b[1m  59/9600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 8ms/step - accuracy: 0.9627 - loss: 0.1281Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m nn_tuned_params = {\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhidden_neurons1\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m180\u001b[39m], \n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhidden_neurons2\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m80\u001b[39m], \n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mactivation\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     19\u001b[39m }\n\u001b[32m     20\u001b[39m grid_nn = GridSearchCV(nn_tuned, nn_tuned_params, n_jobs=\u001b[32m16\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mgrid_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_trainval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trainval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tensorflow/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def create(num_layers, hidden_neurons1=380, hidden_neurons2=80, activation='sigmoid'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Flatten(),\n",
    "        Dense(hidden_neurons1, activation=activation), \n",
    "        Dense(hidden_neurons2, activation=activation),\n",
    "        Dense(10, activation='linear'),\n",
    "        Softmax()\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "nn_tuned = KerasClassifier(create, epochs=5, batch_size=5, hidden_neurons1=380, hidden_neurons2=80, activation='sigmoid')\n",
    "\n",
    "nn_tuned_params = {\n",
    "    'hidden_neurons1': [64, 128, 180], \n",
    "    'hidden_neurons2': [32, 64, 80], \n",
    "    'activation': ['sigmoid', 'relu'], \n",
    "}\n",
    "grid_nn = GridSearchCV(nn_tuned, nn_tuned_params, n_jobs=16)\n",
    "grid_nn.fit(x_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(28,28,1))\n",
    "flatten = Flatten()\n",
    "dense1 = Dense(380)(flatten)\n",
    "dense2 = Dense(180)(dense1) + Dense(180)(flatten)\n",
    "output = Dense(10, activation='softmax')\n",
    "\n",
    "model = tf.keras.models.Model(input=input, outputs=output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
